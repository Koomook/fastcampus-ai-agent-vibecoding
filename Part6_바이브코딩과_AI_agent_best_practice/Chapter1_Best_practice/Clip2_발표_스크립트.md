# Clip 2: 바이브코딩 팁을 자동화시키기 - 발표 스크립트

## 오프닝 (30초)

안녕하세요! 이번 클립에서는 바이브코딩의 효과를 극대화하는 실전 팁을 알아보겠습니다.

Y Combinator의 Startup School에서 공유한 베스트 프랙티스와 현업 개발자들의 경험을 바탕으로, 여러분이 바로 적용할 수 있는 구체적인 전략들을 소개하겠습니다.

---

## Section 1: 새 프로젝트 vs 기존 코드베이스 (2분)

### 핵심 포인트
"바이브코딩은 새로운 프로젝트에서 훨씬 효과적입니다."

왜 그럴까요?

기존 코드베이스에는 세 가지 문제가 있습니다:
1. **암묵적 맥락** - 사람만 아는 비즈니스 로직
2. **문서화 부족** - 주석과 설명 없는 코드
3. **혼재된 인프라** - IaC와 GUI 설정이 섞여있음

실제 사례를 보시죠. 한 개발자가 AWS 리소스를 전부 IaC로 전환하는 작업을 했는데요, 놀랍게도 **고민한 시간보다 구현 시간이 더 짧았다**고 합니다.

### 기존 코드베이스 적용 전략

그렇다면 기존 프로젝트에는 어떻게 적용해야 할까요?

**첫 번째, 하루치 토큰을 문서화에 투자하세요.**
- 코드만 보고 문서화하지 말고
- 인간이 알고 있는 비즈니스 로직도 모두 문서화
- 주석을 빠짐없이 추가

**두 번째, Leaf Nodes부터 시작하세요.**
- 의존성이 적은 부분부터 시작
- 유틸리티 함수, 헬퍼 메서드 같은 말단 기능
- 코어 아키텍처는 나중에!

왜냐하면 코어 아키텍처를 건드리면 전체 시스템이 영향을 받기 때문입니다. 검증되지 않은 AI 코드를 무검토로 적용하는 건 너무 위험합니다.

---

## Section 2: Git을 종교처럼 사용하기 (2분)

### 핵심 메시지
"Git reset --hard를 두려워하지 마세요"

Y Combinator 파트너 Tom의 조언입니다.

**워크플로우는 이렇습니다:**

1. 기능 구현 전: 깨끗한 Git 상태 확인
2. 커밋: 작동하는 상태 저장
3. 문제 발생 시: `git reset --hard`로 되돌리기
4. 해결책 발견 시: 다시 리셋하고 깨끗한 코드에 적용

왜 이렇게 해야 할까요?

LLM이 여러 번 시도하면서 "크러스트(crust)" 레이어가 쌓입니다. 4-6번의 프롬프트 끝에 해결책을 찾아도, 코드는 지저분해요.

**더 나은 방법은:**
- 해결책만 가져오기
- 깨끗한 코드베이스에 한 번에 적용
- 깔끔한 구현 완성

---

## Section 3: 테스트 전략 (2분)

### 고수준 통합 테스트
"저수준 단위 테스트는 LLM의 기본 설정입니다. 우리는 다르게 접근해야 합니다."

**나쁜 예:**
```python
def test_calculate_discount():
    assert calculate_discount(100, 0.1) == 90
```

이런 테스트는 내부 구현을 테스트합니다.

**좋은 예:**
```python
def test_user_purchase_flow():
    # 1. 사용자 로그인
    # 2. 장바구니 추가
    # 3. 결제 진행
    # 4. 주문 확인
```

실제 사용자가 클릭하는 전체 흐름을 테스트하세요. 이렇게 하면 LLM이 불필요한 변경을 했을 때 바로 잡아낼 수 있습니다.

---

## Section 4: Bash의 힘 (1.5분)

### 자동화의 마법
"Claude Code는 Bash를 기가막히게 사용합니다"

실제 예시를 볼까요?

**DNS 설정:**
```bash
User: "Cloudflare DNS에 A 레코드 추가해줘"

Claude Code가 자동으로:
- API 인증
- 레코드 조회
- 추가 API 호출
- 변경 확인
```

**Heroku 배포:**
```bash
User: "Heroku에 배포하고 환경 변수 설정해줘"

Claude Code가:
- heroku create
- git remote 추가
- 환경 변수 설정
- 배포 및 로그 확인
```

이게 바로 LLM provider들이 CLI를 만드는 이유입니다. Bash는 미래입니다.

---

## Section 5: 생산성 도구들 (2분)

### 음성 입력
**타이핑: 60단어/분**
**음성 입력: 140단어/분**

Aqua 같은 도구를 사용하면 생산성이 2배가 됩니다. 게다가 문법 오류도 LLM이 알아서 이해합니다.

### 스크린샷
UI 버그를 보여주거나 다른 사이트 디자인을 참고할 때 스크린샷을 붙여넣으세요. 천 마디 말보다 한 장의 이미지가 낫습니다.

### Git Worktree로 병렬 작업
제가 사용하는 워크플로우를 소개합니다:

1. Linear issue 이름으로 worktree 생성
2. task.md 파일 자동 생성
3. Claude Code 세션 시작

이렇게 하면 여러 작업을 병렬로 돌릴 수 있어서 정말 편합니다.

---

## Section 6: 기술 스택 선택 (1.5분)

### 성숙한 프레임워크가 유리
"Ruby on Rails는 20년 된 프레임워크입니다."

왜 중요할까요?

- **확립된 컨벤션**: "Rails way"가 명확
- **풍부한 훈련 데이터**: 비슷한 코드베이스가 많음
- **AI 성능**: LLM이 더 정확한 코드 생성

비교:
- **Rails, Django**: ⭐⭐⭐⭐⭐ (20년 연식)
- **React**: ⭐⭐⭐⭐ (12년)
- **Rust, Elixir**: ⭐⭐⭐ (상대적으로 신생)

---

## Section 7: 지속적 실험 (1.5분)

### 모델별 강점 활용
"매주 새로운 것을 시도하세요"

**모델 선택 전략:**
- **전체 계획**: Gemini (코드베이스 인덱싱 우수)
- **코드 구현**: Claude Sonnet 3.7 (정확도 최고)
- **디버깅**: Claude Sonnet 3.7 (에러 분석 탁월)
- **리팩토링**: GPT-4.1 또는 Claude

한 가지 모델에만 의존하지 마세요. 상황에 맞는 최적의 모델을 선택하세요.

---

## 클로징 (30초)

### 핵심 요약

오늘 배운 내용을 정리하면:

1. **새 프로젝트**부터 시작하거나 **하루 투자해서 문서화**
2. **Leaf Nodes** (의존성 낮은 부분)부터 시작
3. **Git을 종교처럼** 사용하고 git reset --hard 두려워하지 말기
4. **고수준 통합 테스트** 작성
5. **Bash 자동화** 적극 활용
6. **음성 입력**으로 생산성 2배
7. **성숙한 프레임워크** 선택
8. **지속적으로 실험**하고 최적화

바이브코딩은 단순히 AI에게 코드를 시키는 게 아닙니다. 전문 소프트웨어 엔지니어가 사용하는 베스트 프랙티스를 AI와 함께 적용하는 것입니다.

여러분도 오늘 배운 팁들을 하나씩 적용해보세요. 감사합니다!

---

## 발표 팁

### 타이밍
- 총 소요 시간: 약 13-15분
- 각 섹션은 예시와 함께 설명
- 데모를 포함하면 20분 정도 소요

### 강조 포인트
1. **실전 사례** - Y Combinator, 현업 개발자 경험
2. **구체적인 명령어** - 복붙 가능한 코드 제공
3. **시각 자료** - 다이어그램, 전후 비교
4. **인터랙티브** - 질문 유도, 경험 공유

### Q&A 예상 질문
1. "기존 프로젝트에 적용하는 게 정말 위험한가요?"
2. "Git reset --hard를 자주 사용해도 괜찮나요?"
3. "어떤 AI 모델을 주로 사용하시나요?"
4. "Leaf Nodes를 찾는 자동화 도구가 있나요?"

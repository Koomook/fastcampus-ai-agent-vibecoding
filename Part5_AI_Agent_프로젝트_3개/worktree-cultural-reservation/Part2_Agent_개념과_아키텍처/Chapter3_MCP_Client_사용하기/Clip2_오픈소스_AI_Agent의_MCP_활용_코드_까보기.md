# Clip 2: ì˜¤í”ˆì†ŒìŠ¤ AI Agentì˜ MCP í™œìš© ì½”ë“œ ê¹Œë³´ê¸°

## ğŸ“‹ í•™ìŠµ ê°œìš”
- [mcp-use](https://github.com/mcp-use/mcp-use), [Codex CLI](https://github.com/openai/codex) ë‘ ì˜¤í”ˆì†ŒìŠ¤ì—ì„œ mcp ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ë¶„ì„í•˜ëŠ” ì‹¤ìŠµì„ í†µí•´ í´ë¡œë“œì½”ë“œë¥¼ í™œìš©í•´ ì£¼ë„ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.

### ğŸ¯ í•™ìŠµ ëª©í‘œ
- MCP í´ë¼ì´ì–¸íŠ¸ì˜ 3ë‹¨ê³„ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- ë„êµ¬ ì •ê·œí™”ì™€ ìŠ¤í‚¤ë§ˆ ë³€í™˜ ë©”ì»¤ë‹ˆì¦˜ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤
- LLM ì£¼ë„ ì‹¤í–‰ ë£¨í”„ì˜ ë™ì‘ ì›ë¦¬ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆë‹¤

## ğŸ” STEP 1: MCP í´ë¼ì´ì–¸íŠ¸ 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤

MCP í´ë¼ì´ì–¸íŠ¸ëŠ” **ì—°ê²° â†’ ë„êµ¬ ë°œê²¬ â†’ LLM ì‹¤í–‰**ì˜ 3ë‹¨ê³„ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

| ë‹¨ê³„ | ì—­í•  | í•µì‹¬ ë™ì‘ |
|------|------|-----------|
| â‘  ì—°ê²° | MCPClient | ì„œë²„ ì„¤ì • ë¡œë“œ, Connector ìƒì„±, Session ì´ˆê¸°í™” |
| â‘¡ ë„êµ¬ ë°œê²¬ | MCPSession | ì„œë²„ì˜ tools/resources/prompts ëª©ë¡ ìš”ì²­ |
| â‘¢ LLM ì‹¤í–‰ | MCPAgent | LLMì—ê²Œ ë„êµ¬ ì „ë‹¬, ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ |

### mcp-use ì˜ˆì‹œ ì½”ë“œ

```python
# 1ë‹¨ê³„: ì—°ê²°
client = MCPClient.from_config_file("config.json")
await client.create_all_sessions()  # ëª¨ë“  ì„œë²„ ì—°ê²°

# 2ë‹¨ê³„: ë„êµ¬ ë°œê²¬ (ìë™ ìˆ˜í–‰)
session = client.get_session("linear")
tools = session.list_tools()  # MCP tools ëª©ë¡

# 3ë‹¨ê³„: LLM ì‹¤í–‰
agent = MCPAgent(llm=ChatOpenAI(model="gpt-5"), client=client)
response = await agent.run("linearì—ì„œ ì´ìŠˆ ìƒì„±í•´ì¤˜")
```

## ğŸ› ï¸ STEP 2: ë„êµ¬ ì •ê·œí™”ì™€ ìŠ¤í‚¤ë§ˆ ë³€í™˜

### ë„êµ¬ ì´ë¦„ ì •ê·œí™”
MCP ì„œë²„ì˜ ë„êµ¬ë¥¼ LLMì´ ì‚¬ìš©í•  ë•Œ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ **ì„œë²„ëª… ì ‘ë‘ì‚¬**ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

| ì›ë³¸ ë„êµ¬ëª… | ì •ê·œí™”ëœ ì´ë¦„ | ë³€í™˜ ë¡œì§ |
|------------|--------------|-----------|
| `create_issue` | `linear__create_issue` | mcp-use: `server__tool` |
| `create_issue` | `linear/create_issue` | Codex: `server/tool` |

### ìŠ¤í‚¤ë§ˆ ë³€í™˜ í…Œì´ë¸”

| MCP Schema | OpenAI Function Calling | ë³€í™˜ ê·œì¹™ |
|-----------|------------------------|----------|
| `type: "integer"` | `type: "number"` | integerëŠ” numberë¡œ ì •ê·œí™” |
| `type` ë¯¸ì§€ì • | `type: "string"` | ê¸°ë³¸ê°’ string í• ë‹¹ |
| `properties` ì—†ìŒ | `properties: {}` | ë¹ˆ ê°ì²´ ì‚½ì… |
| ì¤‘ì²© ìŠ¤í‚¤ë§ˆ | ì¬ê·€ì  sanitize | `sanitize_json_schema()` í˜¸ì¶œ |

### Codexì˜ ìŠ¤í‚¤ë§ˆ ë³€í™˜ ì½”ë“œ (Rust)

```rust
// codex-rs/core/src/tools/spec.rs
pub(crate) fn mcp_tool_to_openai_tool(
    fully_qualified_name: String,
    tool: mcp_types::Tool,
) -> Result<ResponsesApiTool, serde_json::Error> {
    let mut input_schema = tool.input_schema;

    // OpenAI í•„ìˆ˜ í•„ë“œ ì²˜ë¦¬
    if input_schema.properties.is_none() {
        input_schema.properties = Some(serde_json::Value::Object(Map::new()));
    }

    let mut serialized = serde_json::to_value(input_schema)?;
    sanitize_json_schema(&mut serialized);  // ì¬ê·€ì  ì •ê·œí™”

    Ok(ResponsesApiTool {
        name: fully_qualified_name,
        parameters: serde_json::from_value(serialized)?,
        strict: false,
    })
}
```

## ğŸ¤– STEP 3: LLM ì£¼ë„ ì‹¤í–‰ ë£¨í”„

### ì‹¤í–‰ íë¦„
```
ì‚¬ìš©ì ì…ë ¥ â†’ LLM íŒë‹¨ â†’ ë„êµ¬ í˜¸ì¶œ â†’ ê²°ê³¼ ë°˜í™˜ â†’ LLM íŒë‹¨ (ë°˜ë³µ)
                â†‘                                       â†“
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìµœëŒ€ max_stepsê¹Œì§€ ë°˜ë³µ â”€â”€â”€â”€â”€â”€â”˜
```

### mcp-useì˜ LangChain ì–´ëŒ‘í„° êµ¬ì¡°

```python
# mcp_use/adapters/langchain_adapter.py
class LangChainAdapter:
    async def _arun(self, **kwargs):
        # â‘  ë„êµ¬ ì‹¤í–‰
        result = await self.tool_connector.call_tool(self.name, kwargs)

        # â‘¡ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (LLMì´ ì½ì„ ìˆ˜ ìˆê²Œ)
        return str(result.content)
```

### Codexì˜ ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰

```rust
// codex-rs/core/src/tools/registry.rs
pub async fn dispatch(&self, invocation: ToolInvocation)
    -> Result<ResponseInputItem, FunctionCallError> {

    let handler = self.handler(tool_name)?;

    // ë³‘ë ¬ ì‹¤í–‰ ì§€ì› ë„êµ¬ëŠ” ë™ì‹œ ì²˜ë¦¬
    if handler.supports_parallel() {
        tokio::spawn(handler.handle(invocation)).await
    } else {
        handler.handle(invocation).await
    }
}
```

## ğŸ’» STEP 4: ë°”ì´ë¸Œì½”ë”©ìœ¼ë¡œ ë¶„ì„í•˜ê¸°

### í”„ë¡¬í”„íŠ¸ 1: mcp-use êµ¬ì¡° íŒŒì•…
```
mcp-use ì €ì¥ì†Œì˜ MCPClient, MCPSession, LangChainAdapter í´ë˜ìŠ¤ ê´€ê³„ë¥¼
í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ë³´ì—¬ì¤˜. ì£¼ìš” ë©”ì„œë“œë§Œ í¬í•¨.
```

### í”„ë¡¬í”„íŠ¸ 2: Codex ë„êµ¬ ë³€í™˜ ë¡œì§
```
codex/codex-rs/core/src/tools/spec.rs íŒŒì¼ì—ì„œ
mcp_tool_to_openai_tool í•¨ìˆ˜ì™€ sanitize_json_schema í•¨ìˆ˜ì˜
ë³€í™˜ ë¡œì§ì„ í…Œì´ë¸”ë¡œ ìš”ì•½í•´ì¤˜.
```

### í”„ë¡¬í”„íŠ¸ 3: ì—ëŸ¬ ì²˜ë¦¬ ë¹„êµ
```
mcp-useì™€ Codexì˜ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ ë°©ì‹ì„
ë¹„êµ ë¶„ì„í•´ì¤˜. ì½”ë“œ ì˜ˆì‹œ í¬í•¨.
```

## âœ… í•µì‹¬ ì •ë¦¬

- **3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤**: ì—°ê²°(Client) â†’ ë°œê²¬(Session) â†’ ì‹¤í–‰(Agent)
- **ë„êµ¬ ì •ê·œí™”**: `server__tool` (mcp-use) ë˜ëŠ” `server/tool` (Codex) í¬ë§·ìœ¼ë¡œ ì¶©ëŒ ë°©ì§€
- **ìŠ¤í‚¤ë§ˆ ë³€í™˜**: MCP ìŠ¤í‚¤ë§ˆë¥¼ OpenAI Function Calling í¬ë§·ìœ¼ë¡œ ì •ê·œí™” (integerâ†’number, ë¹ˆ properties ì‚½ì…)
- **ì‹¤í–‰ ë£¨í”„**: LLMì´ ë„êµ¬ ì„ íƒ â†’ ì‹¤í–‰ â†’ ê²°ê³¼ í‰ê°€ë¥¼ max_stepsê¹Œì§€ ë°˜ë³µ
- **ë³‘ë ¬ ì²˜ë¦¬**: CodexëŠ” `supports_parallel_tool_calls` í”Œë˜ê·¸ë¡œ ë™ì‹œ ì‹¤í–‰ ì§€ì›

## ğŸ“– ì°¸ê³  ìë£Œ

- mcp-use GitHub: https://github.com/mcp-use/mcp-use
- Codex GitHub: https://github.com/openai/codex

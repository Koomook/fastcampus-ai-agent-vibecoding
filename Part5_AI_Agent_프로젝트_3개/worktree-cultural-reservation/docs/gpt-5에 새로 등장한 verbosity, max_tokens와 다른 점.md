GPT-5에게 긴 응답을 받는 방법: verbosity=high 지정하면 형식은 유지하고, 글만 길게 만들 수 있습니다. 개발자 / PM이라면 반드시 알아야 할 필수 파라미터 verbosity, max_tokens, reasoning_effort 를 알아가세요!

Openai의 이번 업데이트에 응답 길이와 상세도를 조절하기 위한 새로운 파라미터인 verbosity가 도입되었습니다. 

1. verbosity=응답 길이 조절 파라미터
GPT-5 API에 새로 추가된 응답의 길이, 자세함을 직관적으로 조절하는 스타일 지시자입니다. 모델이 간략히 핵심만 말할지, 상세하고 길게 말할지를 힌트로 제공합니다.

- low: 매우 간결. 불필요한 장황함 없이 핵심만 응답합니다
- medium(기본값): 별도 설정 없으면 medium입니다.
- high: 매우 자세. 추가 설명/예시/맥락을 풍부하게 포함. 복잡한 주제의 심층 해설에 적합합니다.

그동안 '조금 더 길거나 짧은 응답'을 바라고 few shot 프롬프팅을 했다면 verbosity 를 실험해보시길 추천드립니다. low/medium/high 한 번씩 해보면서 더 디테일하게 내가 원하는 방향으로 응답을 튜닝할 수 있어요.

2. 잠깐, max_tokens랑 다른 점은?
LLM api 를 사용해보셨다면 max_tokens를 알고 계실겁니다. max_tokens는 모델이 생성하는 최대 토큰 수를 지정하는 겁니다. max_tokens=100이면 100토큰에서 즉시 응답이 종료되며 문장이 끊깁니다. 주로 grade, judge 하는 LLM call 에서 token 개수를 극단적으로 줄여서 사용합니다.

verbosity가 max_tokens와 다른 점은 하드 토큰 제한이 아니라는 점입니다. 예를 들어, 사용자가 “5문단으로 에세이”를 요구하면, verbosity=low여도 5개의 단락을 만듭니다. 단, 각 단락의 길이는 짧아지겠죠?

이렇게 LLM의 응답을 프롬프트보다 프로그래밍적으로 조절하는 확실한 방법이기 때문에 strict한 상황에서 선호되는 편입니다.

3. thinking token에만 영향을 미치는: reasoning effort
답을 내기 전에 모델이 내부적으로 얼마나 깊게 생각할지(낮음/보통/높음)를 조절합니다. 높을수록 thinking token 을 많이 소비하고 비용도 비싸집니다. 하지만 일반적으로 더 복잡한 문제를 푸는데 유리하다고 알려져있죠.


4. 실무 Tip!
- verbose 는 글의 형식을 바꾸지는 않아요. 명확한 지시(예: “5문단”, “3가지 포인트만”)가 있으면 그대로 따르긴합니다. 형식 안에서의 글의 양이 줄거나 늘어요.
- 여전히 max_token 은 빠르고 좋은 솔루션입니다. grade / judge 같은 간단한 태스크는 아주 적은 max_tokens 를 사용해서 토큰을 아끼고 빠른 응답을 받으세요
- verbosity로 “말의 스타일”을 max_tokens 로는 "토큰의 절대적인 개수"를 통제하세요

저는 괜찮은 기능이라고 생각하고 몇 가지 기능을 골라서 실험한 뒤에 적용했습니다! 원하는 길이를 뽑는 데에 좋더라구요. 동일한 크기의 UI 컴포넌트에 글을 채워야 하는데 불렛포인트가 1개만 있을 때는 verbosity=high, 불렛포인트가 3개 있을 때는 low 로 지정했더니 전보다 UI가 이쁘게 보여서 좋았습니다.

여러분은 GPT를 사용할 때 응답 길이를 어떻게 조절하고 계셨나요? 댓글로 어떻게 사용하고 계신지 알려주세요!